from openai import OpenAI
import streamlit as st
import streamlit.components.v1 as stc
import base64
import time
import tempfile
from pathlib import Path

# OpenAI client (new SDK style)
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

st.set_page_config(page_title="ãƒãƒ–ãƒ€ãƒãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«", layout="wide")
st.title("ğŸ¤ ãƒãƒ–ãƒ€ãƒãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«")

# BGMå†ç”Ÿ
audio_path1 = 'sample_music.mp3'

audio_placeholder = st.empty()
with open(audio_path1, "rb") as file_:
    contents = file_.read()

audio_str = "data:audio/ogg;base64,%s" % (base64.b64encode(contents).decode())
audio_html = f"""
    <audio id="bgm-player" autoplay loop>
        <source src="{audio_str}" type="audio/ogg">
        Your browser does not support the audio element.
    </audio>
    <script>
        const audio = document.getElementById("bgm-player");
        audio.volume = 0.5;
    </script>
"""

audio_placeholder.empty()
time.sleep(0.5)
audio_placeholder.markdown(audio_html, unsafe_allow_html=True)

# èª¬æ˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³
explain_1, explain_2 = st.columns([1, 1])

with explain_1:
    st.markdown("""
### ğŸ“ ãƒãƒ–ãƒ€ãƒãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«ã¨ã¯ï¼Ÿ

**ãƒãƒ–ãƒ€ãƒãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«**ã¯ã€  
å‹é”ã®åå‰ã¨â€œã„ã„ã¨ã“ã‚â€ã‚’å…¥åŠ›ã™ã‚‹ã ã‘ã§ã€  
å½¼ã‚‰ãŒãƒ©ãƒƒãƒ—ã§ãƒãƒˆãƒ«ã‚’ç¹°ã‚Šåºƒã’ã‚‹ã‚²ãƒ¼ãƒ ã§ã™ã€‚
""")

with explain_2:
    st.markdown("""
### ğŸ”¥ ã“ã®ã‚²ãƒ¼ãƒ ã®é¢ç™½ã•

- **å‹é”ã‚’å‹æ‰‹ã«æˆ¦ã‚ã›ã‚‹èƒŒå¾³æ„Ÿã¨ãŠã‹ã—ã•**  
- **ãƒ©ãƒƒãƒ—ã‚’é€šã˜ã¦ã€å‹é”ã®é­…åŠ›ã‚’å†ç™ºè¦‹ã§ãã‚‹**
""")

st.markdown("---")
st.markdown("ãµã–ã‘ã¦éŠã‚“ã§ã‚‹ã†ã¡ã«ã€ã¡ã‚‡ã£ã¨æ„Ÿå‹•ã™ã‚‹ã€‚  \nãã‚“ãª**å‹æƒ…å†ç™ºè¦‹ãƒãƒˆãƒ«**ã‚’ã€ãœã²ã©ã†ãã€‚")
st.markdown("---")

col1, col_chat, col2 = st.columns([1.0, 2, 1.0])

# å·¦å´
with col1:
    st.header("ğŸ˜ å·¦ã®ãƒãƒ–ãƒ€ãƒ")
    left_name = st.text_input("åå‰ï¼ˆå·¦ï¼‰", "æ—ã•ã‚“")
    left_traits = [
        st.text_input("é­…åŠ›â‘ ï¼ˆå·¦ï¼‰", "æ¸…æ½”æ„ŸãŒã‚ã‚‹"),
        st.text_input("é­…åŠ›â‘¡ï¼ˆå·¦ï¼‰", "å‰£é“ãŒå¼·ã„"),
        st.text_input("é­…åŠ›â‘¢ï¼ˆå·¦ï¼‰", "è‹±æ¤œäºŒç´š")
    ]

# å³å´
with col2:
    st.header("ğŸ˜ˆ å³ã®ãƒãƒ–ãƒ€ãƒ")
    right_name = st.text_input("åå‰ï¼ˆå³ï¼‰", "ç´°è°·ãã‚“")
    right_traits = [
        st.text_input("é­…åŠ›â‘ ï¼ˆå³ï¼‰", "ãƒ‡ã‚¶ã‚¤ãƒ³ãŒã†ã¾ã„"),
        st.text_input("é­…åŠ›â‘¡ï¼ˆå³ï¼‰", "å˜˜ãŒã†ã¾ã„"),
        st.text_input("é­…åŠ›â‘¢ï¼ˆå³ï¼‰", "SFãŒå¥½ã")
    ]

st.markdown("---")

# STARTãƒœã‚¿ãƒ³
with col_chat:
    if st.button("ğŸ”¥ ãƒ©ãƒƒãƒ—ãƒãƒˆãƒ« STARTï¼"):
        with st.spinner("ãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«ä¸­... ğŸ¤ğŸ’¥"):
            prompt = f"""
ä»¥ä¸‹ã®2äººãŒãƒãƒ–ãƒ€ãƒãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«ã‚’è¡Œã„ã¾ã™ã€‚
ãƒ©ãƒƒãƒ—ã¯åˆè¨ˆ4ã‚¿ãƒ¼ãƒ³ã§ã€äº¤äº’ã«2å›ãšã¤ç™ºè¨€ã—ã¦ãã ã•ã„ã€‚

ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯å¿…ãšä»¥ä¸‹ã®å½¢ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆãƒ©ãƒƒãƒ‘ãƒ¼ã®åå‰ã¨ãƒ©ãƒƒãƒ—ã¯åˆ¥è¡Œï¼‰ï¼š

{left_name}
ãƒ©ãƒƒãƒ—1ï¼ˆ3ã€œ5è¡Œï¼‰
{right_name}
ãƒ©ãƒƒãƒ—2ï¼ˆ3ã€œ5è¡Œï¼‰
{left_name}
ãƒ©ãƒƒãƒ—3ï¼ˆ3ã€œ5è¡Œï¼‰
{right_name}
ãƒ©ãƒƒãƒ—4ï¼ˆ3ã€œ5è¡Œï¼‰

ã€ãƒãƒˆãƒ«å‚åŠ è€…ã€‘
- {left_name} ã®é­…åŠ›: {', '.join(left_traits)}
- {right_name} ã®é­…åŠ›: {', '.join(right_traits)}

ç›¸æ‰‹ã‚’ãƒ‡ã‚£ã‚¹ã‚Šã¤ã¤ã‚‚ã€ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚„å€‹æ€§ã‚’å‡ºã—ã¦ãƒ©ãƒƒãƒ—ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
å‰æŒ¯ã‚Šãªã©ã¯å…¨ãå¿…è¦ãªãã€ä¸Šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æº€ãŸã—ãŸ4ã¤ã®ãƒ•ãƒ­ãƒ¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
1ãƒ•ãƒ­ãƒ¼ã¯50æ–‡å­—
"""

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«ã®å¸ä¼šè€…ã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.9,
                max_tokens=500
            )

            rap_battle = response.choices[0].message.content

            # ãƒ©ãƒƒãƒ—éƒ¨åˆ†ã ã‘æŠ½å‡º
            lines = rap_battle.strip().split("\n")
            flows = []
            buffer = []
            for line in lines:
                if line.strip() in [left_name, right_name]:
                    if buffer:
                        flows.append("\n".join(buffer).strip())
                        buffer = []
                else:
                    buffer.append(line)
            if buffer:
                flows.append("\n".join(buffer).strip())
            # å¤‰æ•°ã«æ ¼ç´
            left_flow_1 = flows[0]
            right_flow_1 = flows[1]
            left_flow_2 = flows[2]
            right_flow_2 = flows[3]
            all_flows = [left_flow_1, right_flow_1, left_flow_2, right_flow_2]


            voice_placeholder = st.empty()

                        # --- 2. éŸ³å£°ç”Ÿæˆ ---
            speech_path = Path(f"speech.mp3")
            with client.audio.speech.with_streaming_response.create(
                model="tts-1",
                voice="nova",  # ã‚‚ã—ãã¯ "coral"
                input="\n".join(all_flows),
                instructions="Speak in a cheerful and positive tone.",
            ) as response:
                response.stream_to_file(speech_path)

            # --- 3. éŸ³å£°å†ç”Ÿ ---
            with open(speech_path, "rb") as file_:
                contents = file_.read()
            voice_str = "data:audio/ogg;base64,%s" % (base64.b64encode(contents).decode())

            voice_html = f"""
                <audio autoplay=True>
                <source src="{voice_str}" type="audio/ogg">
                Your browser does not support the audio element.
                </audio>
            """

            voice_placeholder.markdown(voice_html, unsafe_allow_html=True)

            for idx, flow in enumerate(all_flows):
                # --- 1. ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º ---
                st.markdown("---")
                st.markdown(f"<p>{flow}</p>", unsafe_allow_html=True)


                time.sleep(10)



            # å‹æ•—åˆ¤å®š
            st.markdown("---")
            st.markdown("### ğŸ† å‹æ•—åˆ¤å®š")

            judge_prompt = f"""
ä»¥ä¸‹ã®ãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«ã®å†…å®¹ã‚’èª­ã‚“ã§ã€ã©ã¡ã‚‰ã®ãƒ©ãƒƒãƒ‘ãƒ¼ãŒå‹ã£ãŸã‹ã‚’åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
å‹è€…ã®åå‰ï¼ˆ{left_name} ã¾ãŸã¯ {right_name}ï¼‰ã¨ã€ãã®ç†ç”±ã‚’ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚
ãã®éš›ã€ä¸¡æ–¹ã‚’è¤’ã‚ã€ä¸¡æ–¹ãŒå„ªã‚ŒãŸäººé–“ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚

ã€ãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«å†…å®¹ã€‘
{rap_battle}
"""

            judge_response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ãƒ©ãƒƒãƒ—ãƒãƒˆãƒ«ã®å¯©æŸ»å“¡ã§ã™ã€‚"},
                    {"role": "user", "content": judge_prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )

            judge_result = judge_response.choices[0].message.content
            st.success(judge_result)
